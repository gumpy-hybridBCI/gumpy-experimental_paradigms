gumpy-paradigms
===============

This repository contains implementations of the paradigms there were used to
develop and evaluate ``gumpy``. For instance, they contain a classical motor
imagery task, but also a paradigm in which a subject has to reach to grasp an
object.

Note that the code is already usable, but may not yet be production quality.

Documentation
=============

Documentation for each paradigm can be found within the folder ``doc``,
whereas the code to run the paradigms can be found in the respective
subfolders.

Contributing
============

If you wish to contribute to ``gumpy``'s development then clone the main
repository from github and start coding, test if everything works as expected,
and finally submit patches or open merge requests. Preferrably in this order.

Please try to follow PEP8, or have a look at the formatting of gumpy's code, and
include proper documentation both in your commit messages as well as the source
code.

Additional References
=====================

* www.gumpy.org: For more information about ``gumpy``
* https://github.com/gumpy-hybridBCI: ``gumpy``'s main repository, and additional
  information about contributors and how to cite ``gumpy``
* https://github.com/gumpy-hybridBCI/Gumpy-Deeplearning: gumpy's deep learning models for BCI
* https://www.youtube.com/watch?v=M68GeL8PafE


License
=======

* All code in this repository is published under the MIT License.
  For more details see the LICENSE file.


